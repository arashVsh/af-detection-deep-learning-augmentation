{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fcH576_zfTa",
        "outputId": "5d6e7440-19cf-431e-97bd-df1edd7e0c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW4_GH1tz_id",
        "outputId": "4446ccdc-94a8-46c0-e3fc-c309e1755bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import Normalizer \n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import datetime, os\n",
        "from skimage import data, color\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(tf.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PrrwkxFQ0qY0"
      },
      "outputs": [],
      "source": [
        "from os.path import dirname, join as pjoin\n",
        "import scipy.io as sio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EyoeWK5Zz_sf"
      },
      "outputs": [],
      "source": [
        "normal=  sio.loadmat('/content/drive/MyDrive/NormalRPeaks.mat')\n",
        "af=  sio.loadmat('/content/drive/MyDrive/AfRPeaks.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYO6ySOc8jbi"
      },
      "outputs": [],
      "source": [
        "normalImages=np.empty([normal['NormalRPeaks'].shape[1],360 ,360])\n",
        "afImages=np.empty([af['AfRPeaks'].shape[1], 360,360])\n",
        "\n",
        "normalImagesCropped=np.empty([normal['NormalRPeaks'].shape[1],112 ,112])\n",
        "afImagesCropped=np.empty([af['AfRPeaks'].shape[1], 112,112])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp7mMDln4Cvl"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(0,normal['NormalRPeaks'].shape[1]):\n",
        " print(\"i\")\n",
        " print(i)\n",
        "#  x=np.diff(np.diff(normal['NormalRPeaks'][0][i][0]))\n",
        " x=np.diff(np.array(normal['NormalRPeaks'][0][i][0],dtype=np.int16),2)\n",
        " fig = plt.figure(figsize=(5,5))\n",
        " plt.plot(x[0:-2],x[1:-1])\n",
        " plt.xlim([-500, 500])\n",
        " plt.ylim([-500, 500])\n",
        " plt.axis('off')\n",
        "# plt.show()\n",
        " fig.canvas.draw()       # draw the canvas, cache the renderer\n",
        "\n",
        "# width, height = fig.get_size_inches() * fig.get_dpi()\n",
        "# mplimage = np.fromstring(fig.canvas.tostring_rgb(), dtype='uint8').reshape(height, width, 3)\n",
        "# print(image.shape)\n",
        "\n",
        " data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        " image = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        " image = image[:,:,0]/256\n",
        " normalImages[i,:,:]=image\n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAQEXnQiKFkg"
      },
      "outputs": [],
      "source": [
        "np.save(\"normalImages.npy\", normalImages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qft6vhy7CeG-"
      },
      "outputs": [],
      "source": [
        "def imageCropper(samples, REQUIRED_SIZE: int): # Returns samples with required size\n",
        "    from skimage.transform import resize\n",
        "    cropCount = -1\n",
        "    PADDING_VAL = samples[0][0][0]\n",
        "    ORIGINAL_SIZE = samples.shape[1]\n",
        "\n",
        "    for sample in samples:\n",
        "        sampleMaxCrop = -1\n",
        "        for row in range(ORIGINAL_SIZE):\n",
        "            rowMaxCrop = 0\n",
        "            for col in range(ORIGINAL_SIZE):\n",
        "                if sample[row][col] == sample[row][ORIGINAL_SIZE - 1 - col] == PADDING_VAL:\n",
        "                    rowMaxCrop += 1\n",
        "            if rowMaxCrop < sampleMaxCrop or sampleMaxCrop == -1:\n",
        "                sampleMaxCrop = rowMaxCrop\n",
        "        if sampleMaxCrop < cropCount or cropCount == -1:\n",
        "            cropCount = sampleMaxCrop\n",
        "\n",
        "        for col in range(ORIGINAL_SIZE):\n",
        "            colMaxCrop = 0\n",
        "            for row in range(ORIGINAL_SIZE):\n",
        "                if sample[row][col] == sample[ORIGINAL_SIZE - 1 - row][col] == PADDING_VAL:\n",
        "                    colMaxCrop += 1\n",
        "            if colMaxCrop < sampleMaxCrop:\n",
        "                sampleMaxCrop = colMaxCrop\n",
        "        if sampleMaxCrop < cropCount:\n",
        "            cropCount = sampleMaxCrop\n",
        "\n",
        "    print('initial size: ', samples.shape)\n",
        "    cropCount = min(cropCount, int((ORIGINAL_SIZE - REQUIRED_SIZE) / 2))\n",
        "    if cropCount > 0:\n",
        "        samples = samples[:, cropCount:-cropCount, cropCount:-cropCount]\n",
        "        print('after cropping: ', samples.shape)\n",
        "    if samples.shape[1] > REQUIRED_SIZE:\n",
        "        import numpy as np\n",
        "        shrinked_arr = np.empty(\n",
        "            shape=(samples.shape[0], REQUIRED_SIZE, REQUIRED_SIZE))\n",
        "        for i in range(samples.shape[0]):\n",
        "            shrinked_arr[i] = resize(\n",
        "                samples[i], (REQUIRED_SIZE, REQUIRED_SIZE))\n",
        "        print('after interpolation: ', shrinked_arr.shape)\n",
        "        return shrinked_arr\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOcIcPBh8DkB"
      },
      "outputs": [],
      "source": [
        "for i in range(0,af['AfRPeaks'].shape[1]):\n",
        " print(\"i\")\n",
        " print(i)\n",
        " i_new=i\n",
        " x=np.diff(np.array(af['AfRPeaks'][0][i_new][0],dtype=np.int16),2)\n",
        " fig = plt.figure(figsize=(5,5))\n",
        " plt.plot(x[0:-2],x[1:-1])\n",
        " plt.xlim([-500, 500])\n",
        " plt.ylim([-500, 500])\n",
        " plt.axis('off')\n",
        " fig.canvas.draw()       # draw the canvas, cache the renderer\n",
        "\n",
        "\n",
        " data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        " image = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        " image = image[:,:,0]/256\n",
        " afImages[i,:,:]=image\n",
        " \n",
        " print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"afImages.npy\", afImages)"
      ],
      "metadata": {
        "id": "24CSxnUffa67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalImages=np.empty([normal['NormalRPeaks'].shape[1],360 ,360])\n",
        "afImages=np.empty([af['AfRPeaks'].shape[1], 360,360])\n",
        "\n",
        "normalImagesCropped=np.empty([normal['NormalRPeaks'].shape[1],112 ,112])\n",
        "afImagesCropped=np.empty([af['AfRPeaks'].shape[1], 112,112])\n"
      ],
      "metadata": {
        "id": "t0hnq8nNSwfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalImagesCropped = imageCropper(normalImages, 112)\n",
        "np.save(\"normalImagesCropped.npy\", normalImagesCropped)"
      ],
      "metadata": {
        "id": "JvTYKkijPH5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "afImagesCropped = imageCropper(afImages, 112)\n",
        "np.save(\"afImagesCropped.npy\", afImagesCropped)"
      ],
      "metadata": {
        "id": "T-DrC2fTtrhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

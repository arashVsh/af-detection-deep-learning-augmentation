#!/usr/bin/env python
# coding: utf-8

# ## Running Environment

# In[1]:


IS_COLAB = False 
""" Set this as False when running locally and True when running on Colab """
""" Default: Local Running """


# ## Choice of Augmentation

# In[ ]:


AUGMENTED_TO_ORIGINAL_RATIO = 1.2
""" If we have N original AF samples, after augmentation, 
(n x AUGMENTED_TO_ORIGINAL_RATIO) new AF samples will be generated by DCGAN """
""" Set this value as 0 if you don't need augmentation """
""" Please, note that the default value (1.2) is chosen based on the capacity of
 available RAM on Google Colab Pro """


# ## Mount Drive

# In[2]:


#if IS_COLAB:
#    from google.colab import drive
#    drive.mount('/content/drive')
#    get_ipython().run_line_magic('cd', 'drive/MyDrive/Projects/af-detection')
#    # !ls
#

# ## Load libraries

# In[1]:


import numpy as np
from sklearn.utils import shuffle
from Evaluation import evaluation
import gc


# ## Load AF Samples

# In[5]:


af_images = np.load(
"./checkpoint_data/after_preprocessing/afImages.npy") # 360 x 360 AF samples
print('af_images.shape: ', af_images.shape)


# ## Split AF Samples Into 4 Folds

# In[6]:


af_images = shuffle(af_images)
partitionIndex = af_images.shape[0] // 4
af_1 = af_images[:partitionIndex, :, :]
print('af_1.shape: ', af_1.shape)
af_2 = af_images[partitionIndex:2*partitionIndex, :, :]
print('af_2.shape: ', af_2.shape)
af_3 = af_images[2*partitionIndex:3*partitionIndex, :, :]
print('af_3.shape: ', af_3.shape)
af_4 = af_images[3*partitionIndex:, :, :]
print('af_4.shape: ', af_4.shape)
del af_images
gc.collect()


# ## Generate AF Samples If Needed

# In[7]:


augment_1 = None
augment_2 = None
augment_3 = None
augment_4 = None

if AUGMENTED_TO_ORIGINAL_RATIO > 0:
    from DCGAN import augmentation
    n_fakeImagesEachFold = int(partitionIndex*AUGMENTED_TO_ORIGINAL_RATIO)
    augment_1 = augmentation(af_1, n_fakeImagesEachFold)
    print('augment_1.shape: ', augment_1.shape)
    augment_2 = augmentation(af_2, n_fakeImagesEachFold)
    print('augment_2.shape: ', augment_2.shape)
    augment_3 = augmentation(af_3, n_fakeImagesEachFold)
    print('augment_3.shape: ', augment_3.shape)
    augment_4 = augmentation(af_4, n_fakeImagesEachFold)
    print('augment_4.shape: ', augment_4.shape)
    del augmentation
    gc.collect()


# ## Load Normal Images

# In[8]:


normal_images = np.load(
"./checkpoint_data/after_preprocessing/normalImages.npy") # 360 x 360 normal samples
print('normal_images.shape: ', normal_images.shape)


# ## Split Normal Images Into 4 Folds

# In[9]:


normal_images = shuffle(normal_images)
partitionIndex = normal_images.shape[0] // 4
normal_1 = normal_images[:partitionIndex, :, :]
print('normal_1.shape: ', normal_1.shape)
normal_2 = normal_images[partitionIndex:2*partitionIndex, :, :]
print('normal_2.shape: ', normal_2.shape)
normal_3 = normal_images[2*partitionIndex:3*partitionIndex, :, :]
print('normal_3.shape: ', normal_3.shape)
normal_4 = normal_images[3*partitionIndex:, :, :]
print('normal_4.shape: ', normal_4.shape)
del normal_images
gc.collect()


# ## Round 1

# In[ ]:


# Use fold 1 for validation
evaluation(normal_4, af_4, augment_4, normal_2, af_2, augment_2,
               normal_3, af_3, augment_3, val_normal=normal_1, val_af=af_1, checkpoint_filepath='./checkpoints/my_checkpoint/best_1', showModelSummary=True)
gc.collect()


# ## Round 2

# In[ ]:


# Use fold 2 for validation
evaluation(normal_1, af_1, augment_1, normal_4, af_4, augment_4,
               normal_3, af_3, augment_3, val_normal=normal_2, val_af=af_2, checkpoint_filepath='./checkpoints/my_checkpoint/best_2')
gc.collect()


# ## Round 3

# In[ ]:


# Use fold 3 for validation
evaluation(normal_1, af_1, augment_1, normal_2, af_2, augment_2,
               normal_4, af_4, augment_4, val_normal=normal_3, val_af=af_3, checkpoint_filepath='./checkpoints/my_checkpoint/best_3')
gc.collect()


# ## Round 4

# In[ ]:


# Use fold 4 for validation
evaluation(normal_1, af_1, augment_1, normal_2, af_2, augment_2,
               normal_3, af_3, augment_3, val_normal=normal_4, val_af=af_4, checkpoint_filepath='./checkpoints/my_checkpoint/best_4')
gc.collect()

